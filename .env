# Kafka Configuration
KAFKA_BOOTSTRAP_SERVERS=localhost:9092

# Writer Agent - LLM Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini
OPENAI_TEMPERATURE=0.7

# Evaluator Agent - Choose LLM Backend
# Set to 'true' to use Ollama (local), 'false' to use OpenAI
USE_OLLAMA=true

# Ollama Configuration (if USE_OLLAMA=true)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# Alternative Ollama Models (uncomment to try):
# OLLAMA_MODEL=mistral
# OLLAMA_MODEL=llama2
# OLLAMA_MODEL=codellama
# OLLAMA_MODEL=phi

# Notes:
# 1. For Ollama:
#    - Install from https://ollama.ai
#    - Run: ollama pull llama3.2
#    - Start: ollama serve
#
# 2. For OpenAI:
#    - Get API key from https://platform.openai.com
#    - Set USE_OLLAMA=false
#    - Add your OPENAI_API_KEY above